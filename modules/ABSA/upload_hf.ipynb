{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (0.23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fatih\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (manager).\n",
      "Your token has been saved to C:\\Users\\fatih\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\", add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/Fatihseidaa/my-absa', endpoint='https://huggingface.co', repo_type='model', repo_id='Fatihseidaa/my-absa')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=\"Fatihseidaa/my-absa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f542b737348108a689b87d3d0222d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79587e13aca425da55630911a1c5b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.state_dict:   0%|          | 0.00/764M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71085e4dc1a46b5b77b6fd592253015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.config:   0%|          | 0.00/4.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a591be00e4460fa49c5d76ff3b65b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.tokenizer:   0%|          | 0.00/4.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Fatihseidaa/my-absa/commit/7548bbc70526a0afd6394e71ec1199093f9a2ccc', commit_message='Upload folder using huggingface_hub', commit_description='', oid='7548bbc70526a0afd6394e71ec1199093f9a2ccc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_folder\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=\"D:\\\\Akademik\\\\Deploy Model\\\\modules\\\\ABSA\\\\checkpoints\\\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\",  # Ganti dengan path ke folder model Anda\n",
    "    path_in_repo=\"\",\n",
    "    repo_id=\"fatihseidaa/my-absa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-19 14:36:03] (2.4.1.post1) ********** \u001b[32mAvailable ATEPC model checkpoints for Version:2.4.1.post1 (this version)\u001b[0m **********\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) ********** \u001b[32mAvailable ATEPC model checkpoints for Version:2.4.1.post1 (this version)\u001b[0m **********\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) \u001b[31mCheckpoint:Fatihseidaa/my-absa is not found, you can raise an issue for requesting shares of checkpoints\u001b[0m\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) No checkpoint found in Model Hub for task: Fatihseidaa/my-absa\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) Load aspect extractor from Fatihseidaa/my-absa\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) config: None\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) state_dict: None\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) model: None\n",
      "[2024-05-19 14:36:03] (2.4.1.post1) tokenizer: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception: expected str, bytes or os.PathLike object, not NoneType Fail to load the model from Fatihseidaa/my-absa! ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:82\u001b[0m, in \u001b[0;36mAspectExtractor.__init__\u001b[1;34m(self, checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m fprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tokenizer_path))\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, pipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyabsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AspectTermExtraction \u001b[38;5;28;01mas\u001b[39;00m ATEPC, available_checkpoints\n\u001b[1;32m----> 5\u001b[0m aspect_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mATEPC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAspectExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFatihseidaa/my-absa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mauto_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# False means load model on CPU\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcal_perplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:131\u001b[0m, in \u001b[0;36mAspectExtractor.__init__\u001b[1;34m(self, checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Fail to load the model from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m! \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    133\u001b[0m             e, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint\n\u001b[0;32m    134\u001b[0m         )\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ATEPCModelList, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe checkpoint you are loading is not from any ATEPC model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception: expected str, bytes or os.PathLike object, not NoneType Fail to load the model from Fatihseidaa/my-absa! "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fatihseidaa/my-absa\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"fatihseidaa/my-absa\")\n",
    "\n",
    "nlp_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitattributes', 'checkpoints.json', 'fast_lcf_atepc.args.txt', 'fast_lcf_atepc.config', 'fast_lcf_atepc.state_dict', 'fast_lcf_atepc.tokenizer']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Ganti dengan nama repository Anda\n",
    "repo_id = \"Fatihseidaa/my-absa\"\n",
    "\n",
    "api = HfApi()\n",
    "files = api.list_repo_files(repo_id=repo_id)\n",
    "\n",
    "# Cetak daftar file yang ada di repository\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222e98f70af947f99f6acce198c04aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.args.txt:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31739c7e78af487facbe7395c2e77c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.config:   0%|          | 0.00/4.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238944711a4d4e7bae29e55a001ea80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.state_dict:   0%|          | 0.00/764M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f095310237e4459aa7e142d65c001394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fast_lcf_atepc.tokenizer:   0%|          | 0.00/4.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m     checkpoint_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(args_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m---> 27\u001b[0m     args_content \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m     29\u001b[0m     config_content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Ganti 'config.json' dengan nama file yang ada di repository Anda\n",
    "checkpoint = \"checkpoints.json\"\n",
    "txt = \"fast_lcf_atepc.args.txt\"\n",
    "configg = \"fast_lcf_atepc.config\"\n",
    "statedict = \"fast_lcf_atepc.state_dict\"\n",
    "tokenizers = \"fast_lcf_atepc.tokenizer\"\n",
    "\n",
    "# Mengunduh file dari Hugging Face\n",
    "checkpoint_path = hf_hub_download(repo_id=repo_id, filename=checkpoint)\n",
    "# Mengunduh file dari Hugging Face\n",
    "args_path = hf_hub_download(repo_id=repo_id, filename=txt)\n",
    "# Mengunduh file dari Hugging Face\n",
    "config_path = hf_hub_download(repo_id=repo_id, filename=configg)\n",
    "# Mengunduh file dari Hugging Face\n",
    "state_dict_path = hf_hub_download(repo_id=repo_id, filename=statedict)\n",
    "tokenizer_path = hf_hub_download(repo_id=repo_id, filename=tokenizers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca isi file (misalnya, jika file adalah file JSON)\n",
    "import json\n",
    "import torch\n",
    "\n",
    "with open(checkpoint_path, \"r\") as json_file:\n",
    "    checkpoint_content = json.load(json_file)\n",
    "with open(args_path, \"r\") as txt_file:\n",
    "    args_content = txt_file.read()\n",
    "try:\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as config_file:\n",
    "        config_content = config_file.read()\n",
    "except UnicodeDecodeError:\n",
    "    # Jika gagal, coba dengan encoding ISO-8859-1\n",
    "    with open(config_path, \"r\", encoding=\"ISO-8859-1\") as config_file:\n",
    "        config_content = config_file.read()\n",
    "state_dict_content = torch.load(state_dict_path)\n",
    "try:\n",
    "    with open(tokenizer_path, \"r\", encoding=\"utf-8\") as tokenizer_file:\n",
    "        tokenizer_content = tokenizer_file.read()\n",
    "except UnicodeDecodeError:\n",
    "    # Jika gagal, coba dengan encoding ISO-8859-1\n",
    "    try:\n",
    "        with open(tokenizer_path, \"r\", encoding=\"ISO-8859-1\") as tokenizer_file:\n",
    "            tokenizer_content = tokenizer_file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # Jika masih gagal, coba dengan encoding 'latin1'\n",
    "        with open(tokenizer_path, \"r\", encoding=\"latin1\") as tokenizer_file:\n",
    "            tokenizer_content = tokenizer_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'D:\\\\Akademik\\\\Deploy Model\\\\modules\\\\ABSA\\\\checkpoints\\\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\\\\fast_lcf_atepc.config' -> 'D:\\\\Akademik\\\\Deploy Model\\\\modules\\\\ABSA\\\\checkpoints\\\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\\\\config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Asumsi file yang ada di direktori lokal\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAkademik\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDeploy Model\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmodules\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mABSA\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfast_lcf_atepc.config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39mrename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfast_lcf_atepc.state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch_model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mrename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfast_lcf_atepc.tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'D:\\\\Akademik\\\\Deploy Model\\\\modules\\\\ABSA\\\\checkpoints\\\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\\\\fast_lcf_atepc.config' -> 'D:\\\\Akademik\\\\Deploy Model\\\\modules\\\\ABSA\\\\checkpoints\\\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\\\\config.json'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Asumsi file yang ada di direktori lokal\n",
    "model_dir = \"D:\\\\Akademik\\\\Deploy Model\\\\modules\\\\ABSA\\\\checkpoints\\\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\"\n",
    "\n",
    "os.rename(os.path.join(model_dir, \"fast_lcf_atepc.config\"), os.path.join(model_dir, \"config.json\"))\n",
    "os.rename(os.path.join(model_dir, \"fast_lcf_atepc.state_dict\"), os.path.join(model_dir, \"pytorch_model.bin\"))\n",
    "os.rename(os.path.join(model_dir, \"fast_lcf_atepc.tokenizer\"), os.path.join(model_dir, \"tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-19 15:09:48] (2.4.1.post1) Load aspect extractor from C:\\Users\\fatih\\.cache\\huggingface\\hub\\models--Fatihseidaa--my-absa\\snapshots\\1570cf94620798358a16cadf75d04158efe89c38\\checkpoints.json\n",
      "[2024-05-19 15:09:48] (2.4.1.post1) config: None\n",
      "[2024-05-19 15:09:48] (2.4.1.post1) state_dict: None\n",
      "[2024-05-19 15:09:48] (2.4.1.post1) model: None\n",
      "[2024-05-19 15:09:48] (2.4.1.post1) tokenizer: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception: expected str, bytes or os.PathLike object, not NoneType Fail to load the model from C:\\Users\\fatih\\.cache\\huggingface\\hub\\models--Fatihseidaa--my-absa\\snapshots\\1570cf94620798358a16cadf75d04158efe89c38\\checkpoints.json! ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:82\u001b[0m, in \u001b[0;36mAspectExtractor.__init__\u001b[1;34m(self, checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m fprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tokenizer_path))\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyabsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AspectTermExtraction \u001b[38;5;28;01mas\u001b[39;00m ATEPC, available_checkpoints\n\u001b[1;32m----> 3\u001b[0m aspect_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mATEPC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAspectExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mauto_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# False means load model on CPU\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcal_perplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# instance inference\u001b[39;00m\n\u001b[0;32m      9\u001b[0m atepc_result \u001b[38;5;241m=\u001b[39m aspect_extractor\u001b[38;5;241m.\u001b[39mpredict([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI love this movie, it is so great!\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe pizza is very delicious, but the waiters are not friendly.\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     10\u001b[0m                          save_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                          print_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# print the result\u001b[39;00m\n\u001b[0;32m     12\u001b[0m                          ignore_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# ignore the error when the model cannot predict the input\u001b[39;00m\n\u001b[0;32m     13\u001b[0m                          )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:131\u001b[0m, in \u001b[0;36mAspectExtractor.__init__\u001b[1;34m(self, checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Fail to load the model from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m! \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    133\u001b[0m             e, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint\n\u001b[0;32m    134\u001b[0m         )\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ATEPCModelList, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe checkpoint you are loading is not from any ATEPC model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception: expected str, bytes or os.PathLike object, not NoneType Fail to load the model from C:\\Users\\fatih\\.cache\\huggingface\\hub\\models--Fatihseidaa--my-absa\\snapshots\\1570cf94620798358a16cadf75d04158efe89c38\\checkpoints.json! "
     ]
    }
   ],
   "source": [
    "from pyabsa import AspectTermExtraction as ATEPC, available_checkpoints\n",
    "\n",
    "aspect_extractor = ATEPC.AspectExtractor(checkpoint_path,\n",
    "                                         auto_device=False,  # False means load model on CPU\n",
    "                                         cal_perplexity=True,\n",
    "                                         )\n",
    "\n",
    "# instance inference\n",
    "atepc_result = aspect_extractor.predict(['I love this movie, it is so great!', 'The pizza is very delicious, but the waiters are not friendly.'],\n",
    "                         save_result=True,\n",
    "                         print_result=True,  # print the result\n",
    "                         ignore_error=True,  # ignore the error when the model cannot predict the input\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "It looks like the config file at 'D:\\Akademik\\Deploy Model\\modules\\ABSA\\checkpoints\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\\config.json' is not a valid JSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\configuration_utils.py:716\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_from_json_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_config_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m commit_hash\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\configuration_utils.py:814\u001b[0m, in \u001b[0;36mPretrainedConfig._dict_from_json_file\u001b[1;34m(cls, json_file)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[1;32m--> 814\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(text)\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Muat model dan tokenizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:523\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    521\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 523\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\configuration_auto.py:928\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    926\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 928\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    929\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    930\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\configuration_utils.py:719\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m     config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m commit_hash\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m):\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like the config file at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid JSON file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    721\u001b[0m     )\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[0;32m    724\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading configuration file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: It looks like the config file at 'D:\\Akademik\\Deploy Model\\modules\\ABSA\\checkpoints\\fast_lcf_atepc_100.CustomDataset_cdw_apcacc_79.79_apcf1_79.43_atef1_66.82\\config.json' is not a valid JSON file."
     ]
    }
   ],
   "source": [
    "# Muat model dan tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unggah ke Hugging Face\n",
    "model.push_to_hub(\"Fatihseidaa/my-absa\")\n",
    "tokenizer.push_to_hub(\"Fatihseidaa/my-absa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
